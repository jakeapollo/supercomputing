{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# A sparse autoencoder architecture\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, dimension, hidden_size, nonlinearity=nn.ReLU(), freeze=True):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(dimension, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, dimension, bias=False)\n",
    "        self.nonlinearity = nonlinearity\n",
    "        if freeze:\n",
    "            self.fc2.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        acts = self.nonlinearity(x)\n",
    "        out = self.fc2(acts)\n",
    "        return out, acts\n",
    "\n",
    "\n",
    "# a dataset of random unit vectors in R^dimension of size dataset_size\n",
    "class RandomUnitVectors(Dataset):\n",
    "    def __init__(self, dataset_size, dimension):\n",
    "        self.dataset_size = dataset_size\n",
    "        self.dimension = dimension\n",
    "        self.data = t.randn(self.dataset_size, self.dimension).to(device)\n",
    "        self.data = self.data / t.norm(self.data, dim=1).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    optimizer,\n",
    "    sparsity_loss_fn,\n",
    "    sparsity_penality,\n",
    "    epochs=1,\n",
    "    checkpoint_freq=10,\n",
    "):\n",
    "    reconstruction_losses = []\n",
    "    sparsity_losses = []\n",
    "    epochs = list(range(epochs))\n",
    "    checked_epochs = []\n",
    "    explained_variances = []\n",
    "    reconstruction_criterion = nn.MSELoss()\n",
    "    compositenesses = []\n",
    "    for epoch in epochs:\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output, acts = model(data)\n",
    "            reconstruction_loss = reconstruction_criterion(output, data)\n",
    "            sparsity_loss = sparsity_loss_fn(acts) / len(data)\n",
    "            loss = reconstruction_loss + sparsity_penality * sparsity_loss\n",
    "            loss.backward()\n",
    "            reconstruction_losses.append(reconstruction_loss.item())\n",
    "            sparsity_losses.append(sparsity_loss.item())\n",
    "            optimizer.step()\n",
    "        if epoch % checkpoint_freq == 0:\n",
    "            checked_epochs.append(epoch)\n",
    "            # calculate explained variance\n",
    "            explained_variance = t.var(output) / t.var(data)\n",
    "            explained_variances.append(explained_variance.item())\n",
    "            compositenesses.append((acts != 0).sum(dim=-1).detach().cpu().numpy().mean())\n",
    "            print(\n",
    "                f\"Epoch {epoch}, reconstruction loss {reconstruction_loss.item()}, \"\n",
    "                f\"sparsity loss {sparsity_loss.item()}, explained variance {explained_variance}, \"\n",
    "                f\"compositeness {compositenesses[-1]}\"\n",
    "            )\n",
    "    out_dict = {\n",
    "        \"reconstruction_losses\": reconstruction_losses,\n",
    "        \"sparsity_losses\": sparsity_losses,\n",
    "        \"all_epochs\": epochs,\n",
    "        \"checked_epochs\": checked_epochs,\n",
    "        \"explained_variances\": explained_variances,\n",
    "        \"compositenesses\": compositenesses,\n",
    "    }\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 50\n",
    "dimension = 768\n",
    "hidden_size = 25000\n",
    "nonlinearity = nn.ReLU()\n",
    "freeze = True\n",
    "sparsity_penality = 1e-10\n",
    "epochs = 100000\n",
    "checkpoint_freq = 2000\n",
    "batch_size = 50\n",
    "learning_rate = 1e-4\n",
    "plot = False\n",
    "model = SAE(dimension, hidden_size, nonlinearity, freeze).to(device)\n",
    "dataset = RandomUnitVectors(dataset_size, dimension)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "sparsity_loss_fn = lambda x: t.norm(x, p=0.5)\n",
    "results = train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    optimizer,\n",
    "    sparsity_loss_fn,\n",
    "    sparsity_penality,\n",
    "    epochs,\n",
    "    checkpoint_freq,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, acts = model(dataset.data)\n",
    "(acts != 0).sum(dim=-1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results[\"all_epochs\"], results[\"reconstruction_losses\"])\n",
    "plt.title(\"Reconstruction Loss\")\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(results[\"all_epochs\"], results[\"sparsity_losses\"])\n",
    "plt.title(\"Sparsity Loss\")\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(results[\"checked_epochs\"], results[\"explained_variances\"])\n",
    "plt.title(\"Explained Variance\")\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(results[\"checked_epochs\"], results[\"compositenesses\"])\n",
    "plt.title(\"Compositeness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# parameters\n",
    "dfn = 1  # replace with your degrees of freedom numerator\n",
    "dfd = 767  # replace with your degrees of freedom denominator\n",
    "x = 0.203  # the threshold for the tail\n",
    "\n",
    "# compute the survival function (1 - CDF)\n",
    "tail_prob = stats.f.cdf(x, dfn, dfd)\n",
    "\n",
    "print(\n",
    "    f\"The probability that a variable from an F-distribution with {dfn} and {dfd} degrees of freedom exceeds {x} is {tail_prob}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 25000**266\n",
    "len(str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_explains_variance(variance_explained, dimension, compositeness):\n",
    "    dfd = compositeness\n",
    "    dfn = dimension - compositeness\n",
    "    x = 1 / variance_explained - 1\n",
    "    x = x * dfd / dfn\n",
    "    return stats.f.cdf(x, dfn, dfd)\n",
    "\n",
    "\n",
    "dimension = 768\n",
    "compositenesses = np.array(range(60, 80))\n",
    "variance = 0.9\n",
    "probs = [prob_explains_variance(variance, dimension, c) for c in compositenesses]\n",
    "plt.plot(compositenesses, np.log10(probs))\n",
    "samples = np.array([-compositeness * np.log10(25000) for compositeness in compositenesses[1:]])\n",
    "plt.plot(compositenesses[1:], samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supercompute-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
